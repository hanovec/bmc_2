# app.py
#
# Streamlit verze Business Model Canvas Navig치toru.
# Pro spu코t캩n칤 je nutn칠 m칤t nastaven칳 GOOGLE_API_KEY v tajn칳ch kl칤캜칤ch (Secrets) Streamlitu.

import streamlit as st
import os
import json
import google.generativeai as genai

# ==============================================================================
# --- KONFIGURA캛N칈 SEKCE ---
# Parametry jsou zachov치ny p콏esn캩 podle p콢vodn칤ho Colab notebooku.
# ==============================================================================

# Prioritizovan칳 seznam model콢 (s vr치cenou verz칤 2.5 flash)
PRIORITY_MODEL_STEMS = [
    "gemini-2.5-flash-preview-05-20",  # Va코e preferovan치 preview verze
    "gemini-1.5-flash-latest",          # Stabiln칤, rychl칳 fallback
    "gemini-1.5-pro-latest",            # V칳konn캩j코칤 fallback
    "gemini-pro",                       # 말roce dostupn칳 fallback
]

# Konfigurace generov치n칤
GENERATION_CONFIG = {
    "temperature": 1.5,
    "top_p": 0.95,
    "max_output_tokens": 65536,
}

# Bezpe캜nostn칤 nastaven칤
SAFETY_SETTINGS = [
    {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
]

# --- Prompty pro LLM ---

LLM_EXPERT_QUESTION_PLANNER = """
You are an expert strategy consultant and a master of the Alex Osterwalder Business Model Canvas methodology. Your task is to create a structured, comprehensive questioning plan to guide a user through a deep-dive description of their IT Reseller/System Integrator business.

Your output MUST be a valid JSON list of 9 objects, one for each core block of the Business Model Canvas. The order should be logical (Customers/Value -> Operations -> Finances). Each object must have the following four keys:
1. "key": The standard snake_case identifier for the block (e.g., "customer_segments").
2. "question": The main, user-friendly question for the block.
3. "coverage_points": A list of 3-4 critical sub-questions or topics the user MUST consider to provide a complete answer for that block. These should be insightful and cover the nuances of the methodology.
4. "examples": A list of 3-4 short, relevant examples for an IT Reseller/System Integrator.

Example of one object in the list:
{
  "key": "value_propositions",
  "question": "Now, let's detail your Value Propositions. What value do you deliver to your customers?",
  "coverage_points": [
    "Which specific customer problem are you solving or which need are you satisfying?",
    "What bundle of products and services are you offering to each segment?",
    "How does your offering differ from competitors (e.g., is it about performance, price, design, convenience)?",
    "Are you offering something new and disruptive, or improving an existing solution?"
  ],
  "examples": ["Managed Cybersecurity (SOC-as-a-Service)", "Custom Cloud Migration Projects", "Hardware procurement with expert lifecycle advice", "24/7 Premium Technical Support"]
}

Generate ONLY the JSON list and nothing else.
"""

# !!! D콡LE콯IT칄: Nahra캞te n치sleduj칤c칤 z치stupn칠 texty va코imi skute캜n칳mi prompty!
LLM_DEEP_ANALYSIS_PERSONA_V2 = """
**[Z츼STUPN칗 TEXT - NAHRA캝TE SV칗M SKUTE캛N칗M PROMPTEM PRO ANAL칗ZU]**
You are a top-tier business strategist. Analyze the provided Business Model Canvas data for an IT company.
- Identify key strengths and weaknesses in each block.
- Point out potential misalignments between blocks (e.g., value proposition doesn't match customer segment needs).
- Summarize the overall coherence and viability of the business model.
- Present the analysis in a structured, easy-to-read format using Markdown.
"""

LLM_INNOVATION_SUGGESTION_PERSONA_V2 = """
**[Z츼STUPN칗 TEXT - NAHRA캝TE SV칗M SKUTE캛N칗M PROMPTEM PRO N츼VRHY]**
You are a creative innovation consultant specializing in the IT sector. Based on the user's business model data and the strategic analysis, generate actionable, innovative suggestions.
- For each BMC block, provide 1-2 concrete, creative ideas for improvement or new opportunities.
- Ideas should be relevant to an IT Reseller/System Integrator.
- Explain the potential benefit of each suggestion.
- Present the suggestions in a clear, compelling format using Markdown.
"""

# ==============================================================================
# --- POMOCN칄 FUNKCE ---
# ==============================================================================

@st.cache_resource
def initialize_model():
    """Inicializuje a cachuje Gemini model pro celou session."""
    try:
        api_key = st.secrets["GOOGLE_API_KEY"]
        genai.configure(api_key=api_key)
    except Exception as e:
        st.error(f"Chyba p콏i konfiguraci API: Ujist캩te se, 쬰 m치te v Streamlit Secrets nastaven칳 'GOOGLE_API_KEY'. Detaily: {e}")
        st.stop()

    try:
        model_name_to_use = None
        available_models = [m for m in genai.list_models() if "generateContent" in m.supported_generation_methods]
        for model_stem in PRIORITY_MODEL_STEMS:
            found_model = next((m for m in available_models if model_stem in m.name and 'vision' not in m.name.lower()), None)
            if found_model:
                model_name_to_use = found_model.name
                break
        
        if not model_name_to_use:
            st.error("Nepoda콏ilo se naj칤t 쮂멳n칳 z prioritn칤ch Gemini model콢. Zkontrolujte dostupnost model콢 ve va코칤 oblasti a p콏칤stup va코eho projektu k preview verz칤m.")
            st.stop()
            
        model = genai.GenerativeModel(
            model_name=model_name_to_use,
            generation_config=GENERATION_CONFIG,
            safety_settings=SAFETY_SETTINGS
        )
        return model
    except Exception as e:
        st.error(f"Kritick치 chyba p콏i inicializaci modelu: {e}")
        st.stop()

def ask_gemini_sdk(model, prompt_text: str, temperature: float = None) -> str:
    """Ode코le prompt na Gemini a vr치t칤 odpov캩캞."""
    config_overrides = {}
    if temperature is not None:
        config_overrides['temperature'] = float(temperature)

    try:
        response = model.generate_content(prompt_text, generation_config=config_overrides)
        if response.parts:
            return response.text.strip()
        elif response.prompt_feedback and response.prompt_feedback.block_reason:
            return f"AI_ERROR: V치코 prompt byl z bezpe캜nostn칤ch d콢vod콢 zablokov치n ({response.prompt_feedback.block_reason.name})."
        else:
            return "AI_ERROR: Model vr치til ne칰plnou odpov캩캞."
    except Exception as e:
        return f"AI_ERROR: B캩hem vol치n칤 API nastala chyba: {type(e).__name__}."

def reset_session():
    """Vynuluje session state a spust칤 aplikaci od za캜치tku."""
    st.session_state.clear()
    st.rerun()

# ==============================================================================
# --- HLAVN칈 LOGIKA APLIKACE ---
# ==============================================================================

# Nastaven칤 str치nky
st.set_page_config(page_title="BMC Navigator", page_icon="游", layout="wide")
st.title("游 BMC Navigator")
st.markdown("V치코 AI byznys kou캜 pro tvorbu a inovaci Business Model Canvas.")

# Inicializace session state
if 'app_stage' not in st.session_state:
    st.session_state.app_stage = 'welcome'
    st.session_state.question_plan = []
    st.session_state.current_question_index = 0
    st.session_state.bmc_data = {}
    st.session_state.analysis_result = ""
    st.session_state.suggestions_result = ""

# Inicializace modelu
model = initialize_model()

# --- F치ze 1: 칔vod a generov치n칤 pl치nu ---
if st.session_state.app_stage == 'welcome':
    st.info("Jsem tu, abych v치m pomohl zmapovat a inovovat v치코 IT byznys model. Spole캜n캩 projdeme v코ech 9 blok콢 Business Model Canvas.")
    if st.button("Jdeme na to!"):
        with st.spinner("P콏ipravuji pro v치s personalizovan칳 pl치n dotazov치n칤..."):
            plan = ask_gemini_sdk(model, LLM_EXPERT_QUESTION_PLANNER, temperature=0.2)
            if "AI_ERROR" in plan:
                st.error(f"Nepoda콏ilo se vytvo콏it pl치n: {plan}")
            else:
                try:
                    cleaned_json_text = plan.strip().lstrip("```json").rstrip("```").strip()
                    st.session_state.question_plan = json.loads(cleaned_json_text)
                    st.session_state.app_stage = 'questioning'
                    st.rerun()
                except (json.JSONDecodeError, ValueError) as e:
                    st.error(f"Chyba p콏i zpracov치n칤 pl치nu od AI: {e}")

# --- F치ze 2: Dotazov치n칤 ---
elif st.session_state.app_stage == 'questioning':
    idx = st.session_state.current_question_index
    plan = st.session_state.question_plan
    
    if idx < len(plan):
        q_config = plan[idx]
        st.progress((idx + 1) / len(plan))
        st.subheader(f"Oblast {idx + 1}/{len(plan)}: {q_config.get('key', 'Nezn치m칳 blok').replace('_', ' ').title()}")
        
        st.markdown(f"**{q_config.get('question', '')}**")

        with st.expander("Body k zamy코len칤 a p콏칤klady"):
            st.markdown("###### Pro komplexn칤 odpov캩캞 zva쬾e:")
            for point in q_config.get('coverage_points', []):
                st.markdown(f"- {point}")
            st.markdown("---")
            st.markdown(f"**P콏칤klady:** *{', '.join(q_config.get('examples', []))}*")

        answer = st.text_area("Va코e odpov캩캞:", key=f"answer_{idx}", height=200)

        col1, col2, col3 = st.columns([1,1,5])
        with col1:
            if st.button("Dal코칤 ot치zka", type="primary"):
                if len(answer.strip()) < 25:
                    st.warning("Odpov캩캞 je velmi stru캜n치. Zkuste pros칤m p콏idat v칤ce detail콢 pro lep코칤 anal칳zu.")
                else:
                    st.session_state.bmc_data[q_config.get('key')] = answer.strip()
                    st.session_state.current_question_index += 1
                    st.rerun()
        with col2:
             if st.button("P콏esko캜it"):
                st.session_state.bmc_data[q_config.get('key')] = "Skipped"
                st.session_state.current_question_index += 1
                st.rerun()
    else:
        st.success("Skv캩l치 pr치ce! Zmapovali jsme cel칳 v치코 byznys model.")
        st.session_state.app_stage = 'analysis'
        st.rerun()

# --- F치ze 3 & 4: Anal칳za a N치vrhy ---
elif st.session_state.app_stage == 'analysis':
    with st.spinner("Prov치d칤m hloubkovou strategickou anal칳zu va코ich odpov캩d칤..."):
        bmc_data_string = "\n".join([f"- {key}: {value}" for key, value in st.session_state.bmc_data.items() if value != "Skipped"])
        analysis_prompt = f"{LLM_DEEP_ANALYSIS_PERSONA_V2}\n\nHere is the BMC data from the user:\n{bmc_data_string}"
        st.session_state.analysis_result = ask_gemini_sdk(model, analysis_prompt, temperature=0.8)

    with st.spinner("Na z치klad캩 anal칳zy generuji inovativn칤 n치vrhy..."):
        suggestion_prompt = (
            f"{LLM_INNOVATION_SUGGESTION_PERSONA_V2}\n\n"
            f"**User's Business Model Canvas Data:**\n{bmc_data_string}\n\n"
            f"**Strategic Analysis Summary:**\n{st.session_state.analysis_result}\n\n"
            "Now, generate the innovation suggestions based on all the above information."
        )
        st.session_state.suggestions_result = ask_gemini_sdk(model, suggestion_prompt, temperature=1.2)
    
    st.session_state.app_stage = 'done'
    st.rerun()

# --- F치ze 5: Zobrazen칤 v칳sledk콢 ---
elif st.session_state.app_stage == 'done':
    st.balloons()
    st.header("游꿀 Hotovo! Zde jsou v칳sledky.")

    with st.expander("Va코e zadan칠 informace (Business Model Canvas)", expanded=False):
        for key, value in st.session_state.bmc_data.items():
            st.markdown(f"##### {key.replace('_', ' ').title()}")
            st.markdown(f"> {value}")

    st.markdown("---")
    st.header("游늵 Strategick치 Anal칳za")
    st.markdown(st.session_state.analysis_result)

    st.markdown("---")
    st.header("游눠 N치vrhy Inovac칤")
    st.markdown(st.session_state.suggestions_result)

    st.markdown("---")
    if st.button("Za캜칤t znovu"):
        reset_session()
